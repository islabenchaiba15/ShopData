
# ğŸª ShopData â€” Data Warehouse & Analytics Project

A complete **data warehousing and analytics solution** built on PostgreSQL using the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold). This project demonstrates end-to-end data engineering: from raw CSV ingestion, through data cleansing and transformation, to business-ready analytical views and reports.

---

## ğŸ—ï¸ Data Architecture

The project follows the **Medallion Architecture** with three layers:

![Data Architecture](docs/data_architecture.png)

| Layer | Purpose | Implementation |
|-------|---------|----------------|
| **ğŸ¥‰ Bronze** | Raw data ingestion from CSV source files | Tables created via `bronzeLayer.sql`, data loaded with Python (`psycopg2`) |
| **ğŸ¥ˆ Silver** | Data cleansing, standardization & normalization | Transformations in `silverLayer.sql` (deduplication, type casting, formatting) |
| **ğŸ¥‡ Gold** | Business-ready dimension, fact & report views | Star schema views + analytical reports in `goldLayer.sql` |

---

## ğŸ“– Project Overview

### What This Project Does

1. **Data Ingestion** â€” Loads raw CSV data from two source systems (CRM & ERP) into PostgreSQL bronze tables.
2. **Data Cleansing** â€” Deduplicates records, standardizes formats (gender, marital status, country names), fixes data types, and handles nulls.
3. **Data Modeling** â€” Creates a **star schema** with dimension views (`dim_customers`, `dim_products`) and a fact view (`fact_sales`).
4. **Advanced Analytics** â€” Builds report views with KPIs like customer lifetime value, product revenue segmentation, recency analysis, and spending tiers.

### Skills Demonstrated

- SQL Development & PostgreSQL
- Data Architecture (Medallion Architecture)
- ETL Pipeline Development
- Data Modeling (Star Schema)
- Data Analytics & Reporting
- Python (data loading with `psycopg2`)

---

## ï¿½ Data Sources

Data is sourced from two systems:

### CRM (Customer Relationship Management)
| File | Description |
|------|-------------|
| `cust_info.csv` | Customer demographics (ID, name, gender, marital status) |
| `prd_info.csv` | Product catalog (name, cost, line, dates) |
| `sales_details.csv` | Sales transactions (orders, quantities, prices) |

### ERP (Enterprise Resource Planning)
| File | Description |
|------|-------------|
| `CUST_AZ12.csv` | Customer details (birth date, gender) |
| `LOC_A101.csv` | Customer locations (country) |
| `PX_CAT_G1V2.csv` | Product categories & subcategories |

---

## ğŸ¥‰ Bronze Layer â€” `bronzeLayer.sql`

Creates the `bronze` schema and raw tables that mirror the CSV structure exactly.

**Tables created:**
- `bronze.crm_cust_info` â€” CRM customer info
- `bronze.crm_prd_info` â€” CRM product info
- `bronze.crm_sales_details` â€” CRM sales transactions
- `bronze.erm_customers` â€” ERP customer details
- `bronze.erm_customer_location` â€” ERP customer locations
- `bronze.erm_product_category` â€” ERP product categories

> Data is loaded into bronze tables using a Python script with `psycopg2`.

---

## ğŸ¥ˆ Silver Layer â€” `silverLayer.sql`

Runs as a **single execution block** (`DO $$ BEGIN...END $$`). Cleans and transforms bronze data into analysis-ready tables.

**Key transformations:**
| Table | Transformations Applied |
|-------|------------------------|
| `silver.crm_cust_info` | Deduplication via `ROW_NUMBER()`, name trimming, gender/marital status standardization |
| `silver.crm_prd_info` | Category ID extraction, product line mapping (Râ†’Road, Mâ†’Mountain, etc.), end date via `LEAD()` |
| `silver.crm_sales_details` | Integerâ†’Date conversion, negative sales/price correction, null handling |
| `silver.erm_customers` | "NAS" prefix removal, future birth date nullification, gender standardization |
| `silver.erm_customer_location` | Dash removal from IDs, country name standardization (USAâ†’United States, DEâ†’Germany) |
| `silver.erm_product_category` | Direct copy (data is clean) |

---

## ğŸ¥‡ Gold Layer â€” `goldLayer.sql`

Creates the **star schema** views (dimensions + facts) and **advanced report views**, all in a single executable script.

### Dimension Views
| View | Description |
|------|-------------|
| `gold.dim_customers` | Customer dimension joining CRM info + ERP details + ERP location |
| `gold.dim_products` | Product dimension joining CRM products + ERP categories (active products only) |

### Fact View
| View | Description |
|------|-------------|
| `gold.fact_sales` | Sales fact table linking transactions to customer and product dimensions |

### Report Views
| View | Description |
|------|-------------|
| `gold.rpt_product_report` | Product KPIs: revenue segmentation, order metrics, lifespan, recency, avg revenue |
| `gold.rpt_customer_report` | Customer KPIs: spending segmentation, order metrics, lifespan, recency, avg revenue |

### Data Model

![Data Model](docs/data_model.png)

---

## ğŸ“ˆ Advanced Data Analysis â€” `advancedDataAnalysis.sql`

Standalone analytical queries for deeper insights:

- **Monthly Sales Summary** â€” Revenue, customer count, and quantity by month/year
- **Cumulative Yearly Sales** â€” Running total of sales across years
- **Product Revenue Trends** â€” Year-over-year product revenue comparison with trend analysis
- **Product Cost Categories** â€” Segmentation into High/Medium/Low cost tiers
- **Customer Spending Segmentation** â€” VIP / Regular / New customer classification
- **Customer Type Distribution** â€” Count of customers per segment

---

## ğŸ“‚ Repository Structure

```
ShopData/
â”‚
â”œâ”€â”€ datasets/                          # Raw source data (CSV files)
â”‚   â”œâ”€â”€ source_crm/                    # CRM system exports
â”‚   â”‚   â”œâ”€â”€ cust_info.csv              # Customer demographics
â”‚   â”‚   â”œâ”€â”€ prd_info.csv               # Product catalog
â”‚   â”‚   â””â”€â”€ sales_details.csv          # Sales transactions
â”‚   â””â”€â”€ source_erp/                    # ERP system exports
â”‚       â”œâ”€â”€ CUST_AZ12.csv              # Customer details
â”‚       â”œâ”€â”€ LOC_A101.csv               # Customer locations
â”‚       â””â”€â”€ PX_CAT_G1V2.csv           # Product categories
â”‚
â”œâ”€â”€ docs/                              # Documentation & diagrams
â”‚   â”œâ”€â”€ data_architecture.png          # Medallion architecture diagram
â”‚   â”œâ”€â”€ data_model.png                 # Star schema diagram
â”‚   â”œâ”€â”€ data_flow.png                  # Data flow diagram
â”‚   â”œâ”€â”€ data_integration.png           # Integration diagram
â”‚   â”œâ”€â”€ ETL.png                        # ETL process diagram
â”‚   â”œâ”€â”€ data_catalog.md                # Field descriptions & metadata
â”‚   â”œâ”€â”€ naming_conventions.md          # Naming guidelines
â”‚   â”œâ”€â”€ data_layers.pdf                # Layer documentation
â”‚   â””â”€â”€ Project_Notes_Sketches.pdf     # Project planning notes
â”‚
â”œâ”€â”€ bronzeLayer.sql                    # Bronze: schema & table creation
â”œâ”€â”€ silverLayer.sql                    # Silver: data cleansing & transformation
â”œâ”€â”€ goldLayer.sql                      # Gold: dimension, fact & report views
â”œâ”€â”€ advancedDataAnalysis.sql           # Advanced analytical queries
â”œâ”€â”€ exploreData.sql                    # Data exploration queries
â”œâ”€â”€ dashboard.pbix                     # Power BI dashboard
â”œâ”€â”€ dashboard.pdf                      # Dashboard export (PDF)
â””â”€â”€ README.md                          # This file
```

---

## ğŸš€ How to Run

### Prerequisites
- **PostgreSQL** installed and running
- **Python 3.x** with `psycopg2` package (for CSV loading)
- **Power BI Desktop** (optional, for dashboard)

### Execution Order

```bash
# 1. Create bronze tables
psql -f bronzeLayer.sql

# 2. Load CSV data into bronze tables (Python script)
python load_data.py

# 3. Transform data into silver layer
psql -f silverLayer.sql

# 4. Create gold layer views (dimensions, facts, reports)
psql -f goldLayer.sql

# 5. Run advanced analysis queries (optional)
psql -f advancedDataAnalysis.sql
```

> **Note:** Each SQL script is idempotent â€” safe to re-run at any time. Tables/views are dropped and recreated on each execution.

---

## ğŸ› ï¸ Tools & Technologies

| Tool | Purpose |
|------|---------|
| **PostgreSQL** | Database engine |
| **Python + psycopg2** | CSV data loading |
| **Power BI** | Dashboard & visualization |
| **Draw.io** | Architecture & data model diagrams |
| **Git + GitHub** | Version control |

---

## ğŸ›¡ï¸ License

This project is licensed under the [MIT License](LICENSE). You are free to use, modify, and share this project with proper attribution.

---

## ğŸŒŸ About Me

Hi! I'm **Islam Benchaiba**, a data engineering enthusiast passionate about building robust data pipelines and analytical solutions.

ğŸ“§ **Contact:** mi.benchaiba@esi-sba.dz
